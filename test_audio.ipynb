{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.audio_compress import LibriTTS\n",
    "from datasets.utils.diskcache import DiskCachedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exist\n",
      "Wave files are resampled to 16000Hz\n",
      "Chunk map loaded from /home/romain/datasets/LibriTTS/debug/16000/full/512_map.pkl\n",
      "Waves files are splited into 512 samples length\n"
     ]
    }
   ],
   "source": [
    "data_not_cache = LibriTTS('/home/romain/datasets/LibriTTS/', sampling_freq=16_000, sample_length=512, max_sample=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LibriTTS' object has no attribute '__iter__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_not_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LibriTTS' object has no attribute '__iter__'"
     ]
    }
   ],
   "source": [
    "data_not_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_not_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache = DiskCachedDataset(data_not_cache, cache_path='/home/romain/datasets/cache/LibriTTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cache \n",
    "for i in range(data_cache.__len__()):\n",
    "    data_cache[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import random\n",
    "\n",
    "# Assume `dataset` is your PyTorch Dataset\n",
    "# Set the number of samples for timing\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate a list of random indices\n",
    "indices = [random.randint(0, len(data_not_cache) - 1) for _ in range(num_samples)]\n",
    "\n",
    "# Time the average access time\n",
    "average_time = timeit.timeit(\n",
    "    stmt=\"data_not_cache[random.choice(indices)]\",\n",
    "    setup=\"from __main__ import data_not_cache, indices, random\",\n",
    "    number=num_samples\n",
    ") / num_samples\n",
    "average_time \n",
    "# around 5ms \n",
    "# it's too slow considering linear increase by the batch size,\n",
    "# charging a 256 batch it will take, 256 * 5ms = 1.280 s\n",
    "# we need to consider caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005280411747000016"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015699946199993064"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume `dataset` is your PyTorch Dataset\n",
    "# Set the number of samples for timing\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate a list of random indices\n",
    "indices = [random.randint(0, len(data_cache) - 1) for _ in range(num_samples)]\n",
    "\n",
    "# Time the average access time\n",
    "average_time = timeit.timeit(\n",
    "    stmt=\"data_cache[random.choice(indices)]\",\n",
    "    setup=\"from __main__ import data_cache, indices, random\",\n",
    "    number=num_samples\n",
    ") / num_samples\n",
    "average_time # around 5ms \n",
    "# it's too slow considering linear increase by the batch size,\n",
    "# charging a 256 batch it will take, 256 * 5ms = 1.280 s\n",
    "# we need to consider caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets.utils.pad_tensors import PadTensors\n",
    "dataset = DataLoader(data_cache, batch_size=100, collate_fn=PadTensors())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "it = iter(dataset)\n",
    "average_time = timeit.timeit(\n",
    "    stmt=\"next(it)\",\n",
    "    setup=\"from __main__ import it\",\n",
    "    number=num_samples\n",
    ") / num_samples\n",
    "average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01626775599997927"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.deterministic = True\n",
    "def ema_parallel(x:torch.tensor, alpha):\n",
    "    \"\"\"\n",
    "    Compute the exponential moving average (EMA) in parallel using PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input sequence of shape (N, T, C) where N is the batch size and T is the sequence length.\n",
    "        alpha (float): Smoothing factor, 0 < alpha < 1.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: EMA of shape (N, T, C).\n",
    "    \"\"\"\n",
    "    # put the temporal dimension at the end\n",
    "    x = torch.permute(x, (0,2,1))\n",
    "    # Compute weights for the convolution\n",
    "    i = torch.arange(x.shape[-1], device=x.device, dtype=torch.int,)  # Indices\n",
    "    weights = (1 - alpha) * (alpha**i)  # Compute weights as a tensor\n",
    "    weights = weights.flip(0).broadcast_to(x.shape[-2], 1, x.shape[-1])    # Pad the input to simulate u_0 = 0\n",
    "    x_padded = F.pad(x, (weights.shape[-1] - 1, 0), mode=\"constant\", value=0.0)  # Pad on the left\n",
    "    ema = F.conv1d(x_padded, weights, groups=x.shape[-2])\n",
    "    ema = torch.permute(ema, (0,2,1))\n",
    "    return ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema_sequential(x:torch.Tensor, alpha: float):\n",
    "    u = torch.zeros_like(x[:, 0])\n",
    "    buffer = []\n",
    "    for x_t in x.unbind(1):\n",
    "        u = alpha * u + (1 - alpha) * x_t\n",
    "        buffer.append(u)\n",
    "    return torch.stack(buffer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1.0, 101.0, step=1.0, requires_grad=True).reshape(1, 10, 10)\n",
    "alpha = torch.tensor(0.9, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_p = ema_parallel(x, alpha).mean()\n",
    "df_dx, df_dy = torch.autograd.grad(ema_p, [x, alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-127.8128)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dx\n",
    "df_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_seq = ema_sequential(x, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ema_seq.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1000,  1.1900,  3.1710,  5.9539,  9.4585, 13.6127, 18.3514, 23.6163,\n",
       "        29.3546, 35.5192])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ema_p[0,:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1000,  1.1900,  3.1710,  5.9539,  9.4585, 13.6127, 18.3514, 23.6163,\n",
       "        29.3546, 35.5192])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ema_seq[0,:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SE-adLIF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
