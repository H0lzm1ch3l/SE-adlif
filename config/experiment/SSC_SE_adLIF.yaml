# @package _global_
defaults:
  - /dataset: ssc

exp_name: SSC_SE_adLIF

# Whether to use a two-layer network
two_layers: true
# SLAYER parameters
alpha: 5.0
c: 0.4
dt: 1.0
# Dropout rate
dropout: 0.15

l1:
  # Which cell to use
  cell: se_adlif
# input size of preprocessed SHD
  input_size: 140
  # number of neurons
  n_neurons: 720
  # Range of tau_u
  tau_u_range: [5, 25]
  # Range of tau_w
  tau_w_range: [60, 300]
  # Factor for reparametrization of a and b (see paper)
  q: 120
  alpha: ${alpha}
  c: ${c}
  dt: ${dt}
l2:
  # Which cell to use
  cell: se_adlif
  input_size: 720
  # number of neurons
  n_neurons: 720

  # Range of tau_u
  tau_u_range: [5, 25]

  # Range of tau_w
  tau_w_range: [60, 300]
  # Factor for reparametrization of a and b (see paper)
  q: 120
  # input size
  alpha: ${alpha}
  c: ${c}
  dt: ${dt}
l_out:
  input_size: 720
  n_neurons: ${dataset.num_classes}
  # Time constant of output layer 
  tau_u_range: [15, 15]
  dt: ${dt}
# Number of epochs
n_epochs: 40

# Batch size
batch_size: 256

# Loss aggregation
loss_agg: mean_membrane_potentials

# Metric tracking
tracking_metric: val_acc
tracking_mode: max

# optimizer parameters
# learning rate of the optimizer
lr: 6e-3
factor: 0.9
patience: 9999
